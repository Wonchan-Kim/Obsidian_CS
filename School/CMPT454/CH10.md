Tree indexes: binary search can be also costy

Pairs of the form <key, pointer> as index entries or just entries. Each index pages contains pointer more than the number of keys, each key serves as a separator for the contents of the pages pointed to by the pointer to its left and right. ![[Pasted image 20250911193016.png]]![[Pasted image 20250911193021.png]]
Index page is the minimum unit consisting index file. 
We can do a binary search of the index file to identify the page containing the first key value that satisfies the range selection and follow the pointer to the page containing the first data record with that key value. Then we can scan the file sequentially from that point to retrieve the other qualifying records. 

Entry in the index file will not contain every information contained in the page, likely to be much smaller than the size of a page, and only one such entry exists per page of the data file. Now the binary search on the index file is much faster than a binary search of the data file.

===Binary search still expensive!===

## ISAM - INDEX SEQUENTIAL ACCESS METHOD
![[Pasted image 20250911195529.png]]
ISAM structure is ===static===. Primary pages are pre-fixed. 
Each tree node is a disk page, and all the data resides in the leaf pages. 
This corresponds to an index that uses Alternative 1, using ![[Pasted image 20250911200147.png]]
It is also possible to create an index with Alternative 2 by storing the data records in the separate file and storing <key, rid> pairs in the leaf pages of the ISAM index. When the file is created, all leaf pages are allocated sequentially and sorted on the search key value. If Alternative 2 or 3 is used, the data records are created and sorted before allocating the leaf pages of the ISAM index. The non-leaf level pages are then allocated. If more pages than primary pages are allocated, allocation of additional pages are required. ![[Pasted image 20250911200758.png]]
Equality selection search, we start at the root node and determine which subtree to search by comparing the value in the search field of the given record with the key values in the node. 
For a range query, the starting point in the data(leaf) level is determined similarly, and data pages are then retrieved sequentially. For inserts and deletes, the over flow pages are used accordingly. ![[Pasted image 20250911202013.png]]
Deletion of an entry k* is handled by simply removing the entry. If this entry is on an overflow page, and the overflow page becomes empty, the page will then be removed. If the entry is on the primary page and deletion makes the primary page as it is, it serves as a place holder for future insertions. 

ISAM has therefore as inherent structural problem; long overflow chains could develop if a number of inserts are made to the same leaf. These significantly impact the time time to retrieve a record. 

## B+ Trees: A Dynamic Index Structure
![[Pasted image 20250911213339.png]]
Since the tree structure grows and shrinks dynamically, it is not feasible to allocate the leaf pages sequentially as in ISAM, where the set of primary leaf pages was static. To retrieve all leaf pages efficiently, we have to link them using page pointers, in form of ===doubly linked list===.
![[Pasted image 20250911213728.png]]
- Operations(insert, delete) on the three keep it balanced
- A minimum occupancy of 50% is guaranteed for each node except for the root. 
- Searching for a record requires just a traversal from the root to the appropriate leaf. Refer to the length of a path from the root to a leaf(any leaf) as the tree is balanced. 
B+ Trees is the structure in that every node contains m entires, where d <= m <= 2d. d is a parameter of the tree, called the order of the tree, and is a measure of the capacity of a tree node. The root node is the only exception. 

### Format of the node
Same as ISAM ![[Pasted image 20250911193016.png]]
Pointer Pi points to the subtree in which all key values K are such that Ki <= K < Ki+1. As special cases, P0 points to a tree in which all key values are less than K1 and Pm points to a tree in which all key values are greater or equal than Km. 

Leaf nodes, denoted as k*. only leaf nodes contain data entries. 
If alternative (2) and (3) is used, leaf entries are <K, I(K)> pairs, just like non-leaf entires. Regardless of the alternative chosen for leaf entries, the leaf pages are chained together in a DDL.

### Search
```
find(searchkey K) returns nodepointer
return tree_search(root,K)
end find

tree_search(root, K) returns nodepointer
if *nodepointer is a leaf, return nodepointer
else
	if K < K1 then return tree_search(Po, K)
	else
		if K >= Km then return tree_search(Pm, K)
		else
			find i such that Ki <= K < Ki+1
			return tree_search(Pi, K)
end tree_search
```
![[Pasted image 20250911222817.png]]
With this example, d = 2, meaning that each node contains between 2 and 4 entries. Each non leaf entry is a <key value, node pointer> pair. The leaf level nodes' entries are data records denoted by k*. 

### Insert
The main idea is to recursively insert the entry by calling the insert algorithm on the appropriate chile node. In case of the node is full, the insertion causes the split. When the node is split, an entry pointing to the node created by the split must be inserted into its parent. If the root is split, a new root node is created and the height of the three increases by 1. 

#### case1 split
![[Pasted image 20250911222817.png]]
Using the same example tree, think of case inserting 8 into the tree. 8 will belong to the left most node, which is already full, indicating the split is required. ![[Pasted image 20250911225019.png]]
Note how the key 5, which discriminates between the split leaf page and its new created sibling, is copied up. We can't just push up as every data entry must appear in  a leaf page. 

Note that as 5 is pushed up, the parent node is also full. In general, we have to split a non leaf node when it is full, containing 2d keys and 2d+1 pointers, and we have to add another index entry to account for a child split. We now have 2d+1 keys and 3d_2 pointers, yielding two minimally full non-lea nodes, each containing d keys and d+1 pointers. This key and a pointer to the second non-leaf node constitute an index entry that must be inserted into the parent of the split non-leaf node. The middle key is thus pushed up the tree, in contrast to the case for a split of a leaf page. 

Now the 17 is pushed up. 
![[Pasted image 20250911230511.png]]
The difference in handling leaf-level and index-level splits arises from the B+tree requirement that all data entries k* must reside in the leaves. This requriement prevent us from pushing up 5. ![[Pasted image 20250911230700.png]]
#### case 2 - redistribution (improved algorithm)![[Pasted image 20250911222817.png]]
Reconsider inserting 8 into the tree. The entry belongs to the left most leaf, which is full. However, the only sibling of this leaf node contains only two entries and can this accommodate more entries. We can therefore handle the insertion 8 with a distribution. We copy up the new low key value on the second leaf. ![[Pasted image 20250911232606.png]]
1. To check if the redistribution is possible, we have to retrieve the sibling. If the sibling is full, we have to split the node anyway. On average, checking whether the redistribution is possible increases I/O for index node splits, especially if we check both siblings. 
2. If a split occurs at the leaf level, need to retrieve the neighbour to adjust the previous and next neighbour pointers with respect to the newly created leaf node. If a leaf node is full, fetch a neighbour node, if it has space and has the same parent, redistribute the entries. 
   If the neighbour has different parent, split the leaf node and adjust the previous and next neighbour pointers in the split node, the newly created neighbour and the old neighbour.

### Delete
	Basic idea behind the algorithm is that we recursively delete the entry by calling the deletion algorithm on the appropriate child node. We usually go down to the leaf node where the entry belongs, remove the entry from there and return all the way back to the root node. 

Special case: Node is at its minimum occupancy before the deletion, making the deletion causes it to go below the occupancy threshold. 

Solution: 
1) Redistribute entries from an adjacent sibling :
   Parent node should also be updated to reflect this change. The key value in the index entry pointing to the second node must be changed to be the lowest search key in the second node. 
2) merge the node with a sibling maintaining minimum occupancy: 
   Parent node must be updated to reflect the change; deleting the index entry for the second node, this index entry is pointed to by the pointer variable oldchildentry when the delete call returns to the parent node. ===if the last entry in the root node is deleted, because one of its children was deleted, the height reduces by 1.===
![[Pasted image 20250914165047.png]]
Deleting 19:
simply remove the leaf page on which it appears, and we are done because the leaf still contains two entries. If we delete 20, however, the leaf contains only one after the deletion, the sibling node contained 20 has three entries, we can redistribute. 
Move entry 24 to the leaf page that contained 20 and ===copy up=== the new splitting key 27, which is the new low key value of the leaf from which we borrowed in the parent. ![[Pasted image 20250914165439.png]]
Deleting 24:
The affected leaf contains only one entry 22* after the deletion, and the sibling contains two entries. We can't use redistribution method, but merging can be used. We can toss the entry <27, pointer to second leaf page> in the parent which pointed to the second leaf page, because the second leaf page is empty after the merge and can be discarded. ![[Pasted image 20250914165924.png]]
Deleting the entry <27, pointer to second leaf page> has created a non-leaf level page with just one entry, which is below the minimum threshold of d=2. Redistribution or merged is required. In either case, we must fetch a sibling. The only sibling of this node contains just two entries, with key entries 5 and 13. Must use merge. 

The situation we have to merge two-non-leafs is exactly the opposite of the situation when we have to split a non-leaf node. We have to split a non-leaf node when it contains 2d keys and 2d+1 pointers and we have to add another key-pointer pair. Since we resort to merging two non-lead nodes only when redistribution is impossible, two nodes must be satisfying the minimum threshold; d keys and d+1 pointers. Hence, we will have ===2d-1 keys and 2d+1 pointers===. Intuitively, the left-most pointer on the second merged node lacks a key value. To see what key value must be combined with this pointer to create a complete index entry, consider the parent of the two nodes being merged. The index entry pointing to one of the merged nodes must be deleted from the parent because the node is about to be discarded. The key value in this entry is precisely the key value we need to complete the new merged node: The entries in the first node being merged, followed by the splitting key value that is pulled down from the parent, followed by the entries in the second non-leaf node gives us a total of 2d keys and 2d+1 pointers, which is a full non-leaf node. 

Consider the merging of two non-leaf nodes in the example. Together, the non-leaf node and the sibling to be merged contain only three entries, and they have a total of five pointers to the leaf nodes. To merge the two nodes, we also need to pull down the index entry in their parent that currently discriminate between these nodes. This index entry has key value 17, and so we create new entry <17, left most child pointer in sibling>, having now four entries and five child pointers which can fit on one page in a tree of order d = 2. Note that pulling down the splitting key 17 means that it will no longer appear in the parent node following the merge. After we merge the affected non-leaf node and its sibling by putting all the entries on one page and discarding the empty sibling page, the new node is the only child of the old root, which can therefore be discarded. 

![[Pasted image 20250914194548.png]]
The remaining case is that of redistribution of entries between non-leaf level pages. To understand this case, consider ![[Pasted image 20250914194808.png]]
intermediate right subtree shown above. 
![[Pasted image 20250916220113.png]]

#### B+ Trees in Practice
### key comparison
B+ Trees height: number of data entries, size of index entires 

size of index entries -> determines the number of index entries that will fit on a page = fanout of the tree

height is proportional to log(fanout of data entries)
number of I/O to retrieve a data entry equal to height

===important to maximize the fan out to minimize the height ===

index entry contains a search key and a page pointer. Size depends on the search key. 
Search key in index entries are used only to direct traffic to appropriate leaf. 
During the comparison at an index-level node, need to identify two index entries with search key values k1 and k2 such that the desired search key is k1 < k < k2. 
===need not store search key values in their entry in index entries===

For example, suppose we have two adjacent index entries in a node, with search key values 'David Smith' and 'Devarakonda ... ' To discriminate between these two values, it is sufficient to store the abbreviated forms 'Da' and 'De.' More generally, the lneaning of the entry 'David Smith' in the B+ tree is that every value in the subtree pointed to by the pointer to the left of 'David Smith' is less than 'David Smith,' and every value in the subtree pointed to by the pointer to the right of 'David Smith' is (greater than or equal to 'David Smith' and) less than 'Devarakonda ... '

This technique is called as prefix key compression or simply key compression.

### Bulk Loading
entries are added in two ways
1) existing collection of data records with a B+tree index on it
   이미 데이터 집합이 있고 그 위에 인덱스가 존재
   즉 새로운 데이터가 추가되면 트리에도 새로운 엔트리르 삽입
2) collection of data records for which we want to create a index on some key fields. 
   빈 트리에서 시작해서 데이터 레코드를 하나씩 삽입
   문제점: 데이터가 많을 시, 레코드 하나마다 루트에서 리프까지 탐색
   
many systems provide ===bulk loading===
1. sort the data entries to be inserted into b+ tree according to the search key k.
![[Pasted image 20250916222005.png]]
2. allocate and empty page to serve as a root and isnert a pointer to the first page of entries into it. 
3. add one entry to the root page for each page of the sorted data entires. Proceed until the root page is full.
   ![[Pasted image 20250916222102.png]]
4. split the root if it is full, push up. ![[Pasted image 20250916222213.png]]
split always occur on the right path!

![[Pasted image 20250916225111.png]]![[Pasted image 20250916225118.png]]
Cost analysis: 
1. data entry generation:
   scan the records, make the data entries to insert
   R(page of records) + E(number of pages to be inserted)
   R + E I/Os
2. data entry sort:
   must be sorted, about 3E I/Os
3. tree insert
   without bulk-loading: each record O(logN)-> NlogN
   bulk-loading: N